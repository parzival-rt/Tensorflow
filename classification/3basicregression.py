# -*- coding: utf-8 -*-
"""3basicRegression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-J-rv9P8fkOjVg6YaOb86uW9V1c_u3Od

#**Basic regression: Predict fuel efficiency**
* This notebook uses the classic Auto MPG Dataset and builds a model to predict the fuel efficiency of late-1970s and early 1980s automobiles. 
* To do this, we'll provide the model with a description of many automobiles from that time period. 
* This description includes attributes like: cylinders, displacement, horsepower, and weight.
"""

!pip install -q seaborn # for pairplot
!pip install -q git+https://github.com/tensorflow/docs # some function tensorflow_docs

import pathlib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import tensorflow_docs as tfdocs
import tensorflow_docs.plots
import tensorflow_docs.modeling

print(tf.__version__)
if tf.__version__ != '2.0.0':
  !pip install tensorflow==2.0.0
  print("** Tensorflow updated **")

"""#**The Auto MPG dataset**
The dataset is available from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/).
"""

datasetPath = keras.utils.get_file("auto-mpg.data", "http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data")
datasetPath

"""Import it using pandas"""

columnNames = ['MPG','Cylinders','Displacement','Horsepower','Weight',
                'Acceleration', 'Model Year', 'Origin']

rawDataset = pd.read_csv(datasetPath, names=columnNames,
                         na_values='?', comment='\t',
                         sep=' ', skipinitialspace=True) #seperator

dataset = rawDataset.copy()
dataset.tail() #[25:35]

"""#**Clean the data**"""

dataset.isna().sum()

dataset = dataset.dropna() # del the raws

"""**The "Origin" column is really categorical, not numeric. So convert that to a one-hot**"""

dataset['Origin'] = dataset['Origin'].map(lambda x:{1:'Usa', 2:'Europe', 3:'Japan'}.get(x))
dataset = pd.get_dummies(dataset, prefix='', prefix_sep='')
dataset.tail()#[25:35]

"""#**Split the data into train and test**
Now split the dataset into a training set and a test set.
"""

trainDataset = dataset.sample(frac=0.8, random_state=0)
testDataset = dataset.drop(trainDataset.index)

"""Let's look at the data distribution quickly"""

sns.pairplot(trainDataset[["MPG", "Cylinders", "Displacement", "Weight"]], diag_kind='kde')

"""####**General statistics in data**"""

trainStats = trainDataset.describe()
trainStats.pop("MPG")
trainStats = trainStats.transpose()
trainStats

"""#**Split features from labels**
* Separate the target value, or "label", from the features. This label is the value that you will train the model to predict.
* This tag is the value we will train to estimate the model.
"""

trainLabels = trainDataset.pop("MPG")
testLabels = testDataset.pop("MPG")

"""#**Normalize the data**
* Look again at the train_stats block above and note how different the ranges of each feature are.

* **Outlier** is a data point that differs significantly from other observations.

> * Lower Outlier = Q1 â€“ (1.5 * IQR)
* Higher Outlier= Q3 + (1.5 * IQR)

![alt text](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQX51DPhHlit_a9OSwyvB-YPj1gv8hsGsHZSOGVE-_emMeTBqgq)
"""

def norm(x):
  return (x - trainStats['mean']) / trainStats['std']
normedTrainData = norm(trainDataset)
normedTestData = norm(testDataset)

normedTrainData

"""**This normalized data is what we will use to train the model.**

#**Build the model**
* Here, we'll use a Sequential model with two densely connected hidden layers, and an output layer that returns a single, continuous value. 
* The model building steps are wrapped in a function, build_model, since we'll create a second model, later on.
"""

def buildModel():
  model = keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=[len(trainDataset.keys())]),
    layers.Dense(64, activation='relu'),
    layers.Dense(1)])
  optimizer = tf.keras.optimizers.RMSprop(0.001)

  model.compile(loss='mse',
                optimizer=optimizer,
                metrics=['mae', 'mse'])
  return model

model = buildModel()

"""Let's use the **'.summary'** method to print a simple description of the model."""

model.summary()

"""Now let's try the model. Let's take 10 examples of training data and call **'model.predict'**"""

exampleBatch = normedTrainData[:10]
exampleResult = model.predict(exampleBatch)
exampleResult

"""It seems to be working :) and gives a result of the expected shape and type.

#**Train The Model**
* Train the model for 1000 epochs and record the training and validation accuracy in the history object.
"""

EPOCHS = 1000
history = model.fit(normedTrainData, trainLabels,
                    epochs=EPOCHS, validation_split=0.2,
                    verbose=0, callbacks=[tfdocs.modeling.EpochDots()])

"""#**Now, using the statistics stored in the history object, let's visualize the model's educational progress.**"""

hist = pd.DataFrame(history.history)
hist['epoch'] = history.epoch
hist.tail()

plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)

plotter.plot({'Basic' : history}, metric="mae")
plt.ylim([0,10])
plt.ylabel('MAE [MPG]')

plotter .plot({'Basic' : history}, metric='mse')
plt.ylim([0,20])
plt.ylabel('MSE [MPG^2]')

"""This graph shows little improvement, or even degradation in the validation error after about 100 epochs. Let's update the model.fit call to automatically stop training when the validation score doesn't improve. We'll use an EarlyStopping callback that tests a training condition for every epoch. If a set amount of epochs elapses without showing improvement, then automatically stop the training."""

model = buildModel()
# The patience parameter is the amount of epochs to check for improvement

earlyStop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)

earlyHistory = model.fit(normedTrainData, trainLabels,
                         epochs=EPOCHS, validation_split=0.2,
                         verbose=0, callbacks=[earlyStop, tfdocs.modeling.EpochDots()])

plotter.plot({'Early Stopping' : earlyHistory}, metric='mae')
plt.ylim([0,10])
plt.ylabel('MAE [MPG]')

"""* The graph shows that on the validation set, the average error is usually around +/- 2 MPG. Is this good? 
* Let's see how well the model generalizes by using the test set, which we did not use when training the model. This tells us how well we can expect the model to predict when we use it in the real world.
"""

loss, mae, mse = model.evaluate(normedTestData, testLabels, verbose=2)
print("Testing set mean abs error : {:5.2f} MPG".format(mae))

"""#**Make predictions**
Finally, predict MPG values using data in the testing set:
"""

testPredictions = model.predict(normedTestData).flatten()
a = plt.axes(aspect='equal')
plt.scatter(testLabels, testPredictions)
plt.xlabel('True Value [MPG]')
plt.ylabel('Predictions [MPG]')
lims = [0,50]
plt.xlim(lims)
plt.ylim(lims)
_ = plt.plot(lims, lims)

"""##**It looks like our model predicts reasonably well. Let's take a look at the error distribution.**"""

error = testPredictions - testLabels
plt.hist(error, bins = 25)
plt.xlabel("Prediction Error [MPG]")
_ = plt.ylabel("Count")

"""#**In Summary**
* Mean Squared Error (MSE) is a common loss function used for regression problems (different loss functions are used for classification problems).
* Similarly, evaluation metrics used for regression differ from classification. A common regression metric is Mean Absolute Error (MAE).
* When numeric input data features have values with different ranges, each feature should be scaled independently to the same range.
* If there is not much training data, one technique is to prefer a small network with few hidden layers to avoid overfitting.
* Early stopping is a useful technique to prevent overfitting.
"""